{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3e58b59",
   "metadata": {},
   "source": [
    "\n",
    "# Trackintel case study - Tracking dataset comparison\n",
    "This notebook presents a case-study to jointly analyse four different tracking datasets using [trackintel](https://github.com/mie-lab/trackintel). \n",
    "Three of the datasets that are used in this case study can not be published to protect the privacy of the participants. You can find an executable example notebook for trackintel here: [binder](https://mybinder.org/v2/gh/mie-lab/trackintel/HEAD?urlpath=https%3A%2F%2Fgithub.com%2Fmie-lab%2Ftrackintel%2Fblob%2Fmaster%2Fexamples%2Ftrackintel_basic_tutorial.ipynb) [code](https://github.com/mie-lab/trackintel/blob/master/examples/trackintel_basic_tutorial.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d2d290",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4ab09af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import psycopg2\n",
    "import json\n",
    "import seaborn as sns\n",
    "from shapely.geometry import Point\n",
    "\n",
    "import trackintel as ti\n",
    "from trackintel.analysis.tracking_quality import temporal_tracking_quality\n",
    "from trackintel.analysis.modal_split import calculate_modal_split\n",
    "from trackintel.visualization.modal_split import plot_modal_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96fbde53",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = \"./temp\"\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "path_to_geolife = r\"E:\\Geolife Trajectories 1.3\\Data_10\"\n",
    "DBLOGIN_FILE = os.path.join(\"../mobility-graph-representation/dblogin.json\")\n",
    "DBLOGIN_FILE = r\"C:\\Users\\henry\\OneDrive\\Programming\\21_mobility-graph-clustering\\dblogin.json\"\n",
    "DBLOGIN_FILE_GC = r\"C:\\Users\\henry\\OneDrive\\Programming\\21_mobility-graph-clustering\\dblogin_source.json\"\n",
    "DBLOGIN_FILE_yumuv = r\"C:\\Users\\henry\\OneDrive\\Programming\\21_mobility-graph-clustering\\dblogin_mielab.json\"\n",
    "\n",
    "with open(DBLOGIN_FILE) as json_file:\n",
    "    LOGIN_DATA = json.load(json_file)\n",
    "\n",
    "with open(DBLOGIN_FILE_GC) as json_file:\n",
    "    LOGIN_DATA_GC = json.load(json_file)\n",
    "\n",
    "with open(DBLOGIN_FILE_yumuv) as json_file:\n",
    "    LOGIN_DATA_YUMUV = json.load(json_file)\n",
    "    \n",
    "con = psycopg2.connect(\n",
    "        dbname=LOGIN_DATA[\"database\"],\n",
    "        user=LOGIN_DATA[\"user\"],\n",
    "        password=LOGIN_DATA[\"password\"],\n",
    "        host=LOGIN_DATA[\"host\"],\n",
    "        port=LOGIN_DATA[\"port\"],\n",
    ")\n",
    "\n",
    "con_gc = psycopg2.connect( # requires ssh tunnel\n",
    "        dbname=LOGIN_DATA_GC[\"database\"],\n",
    "        user=LOGIN_DATA_GC[\"user\"],\n",
    "        password=LOGIN_DATA_GC[\"password\"],\n",
    "        host=LOGIN_DATA_GC[\"host\"],\n",
    "        port=LOGIN_DATA_GC[\"port\"],\n",
    ")\n",
    "\n",
    "con_yumuv = psycopg2.connect( # requires ssh tunnel\n",
    "        dbname=LOGIN_DATA_YUMUV[\"database\"],\n",
    "        user=LOGIN_DATA_YUMUV[\"user\"],\n",
    "        password=LOGIN_DATA_YUMUV[\"password\"],\n",
    "        host=LOGIN_DATA_YUMUV[\"host\"],\n",
    "        port=LOGIN_DATA_YUMUV[\"port\"],\n",
    ")\n",
    "\n",
    "CRS_WGS84 = \"epsg:4326\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "studies = [\"gc1\", \"gc2\", \"yumuv_graph_rep\", \"geolife\"]\n",
    "\n",
    "# for plotting later:\n",
    "study_mapping = {\"gc1\":\"Green Class 1\", \"gc2\": \"Green Class 2\", \"yumuv_graph_rep\": \"Yumuv\", \"geolife\":\"Geolife\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "We include the data from four tracking studies with two different tracking data types.\n",
    "\n",
    "### Green Class 1 & 2 \n",
    "The Green Class 1 & 2 studies were conducted in collaboration with the Swiss Federal Railway Systems (SBB) under the project name [SBB Green Class](https://www.researchgate.net/publication/335858551_Analysis_framework_and_results_of_the_SBB_Green_Class_pilot_studies)\n",
    "In both studies, participants were given full access to all public transport in Switzerland. In addition, the participants from the first Green Class study (Green Class 1) received an electric vehicle and the ones from the second study (Green Class 2) an e-bike. Study participants were tracked with a GNSS-based application (app) that provides partially preprocessed data as staypoints and triplegs.\n",
    "### Geolife\n",
    "The first study is the open-source [Geolife dataset](https://www.microsoft.com/en-us/download/details.aspx?id=52367&from=https%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fdownloads%2Fb16d359d-d164-469e-9fd4-daa38f2b2e13%2F) that covers the movement of employees of Microsoft Research Asia. The dataset is from about 2012 and was still recorded with dedicated GPS-only trackers. As the study took place in an urban area the GPS was unreliable and there are many gaps in the dataset. However, Geolife is still one of the few publicly available tracking datasets.\n",
    "\n",
    "### Yumuv\n",
    "The [yumuv](https://www.research-collection.ethz.ch/handle/20.500.11850/521380) study investigated the impact of a [Mobility-as-a-Service app](https://yumuv.ch/en) that integrates shared e-scooters, e-bikes and public transport. In the yumuv study, participants were divided into control and treatment group and were tracked for three months using an app that already provides staypoints and triplegs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data\n",
    "One main advantage of trackintel is its ability to standardize the preprocessing of tracking data. For this, the different datasets have to be imported to geopandas dataframes that fulfill the requirements described [here](https://trackintel.readthedocs.io/en/latest/modules/model.html)\n",
    "\n",
    "The trackintel data model consists of these different classes:\n",
    "\n",
    "- positionfixes [pfs]: Raw GPS data.\n",
    "- staypoints [sp]: Locations where a user spent a minimal time.\n",
    "- triplegs [tpls]: Segments covered with one mode of transport.\n",
    "- locations [loc]: Clustered staypoints.\n",
    "- trips: Segments between consecutive activity staypoints (special staypoints that are not just waiting points).\n",
    "- tours: Sequences of trips which start and end at the same location (if the column ‘journey’ is True, this location is home).\n",
    "\n",
    "The Geolife dataset consists of only positionfixes while the other datasets are already processed to staypoints and triplegs by the tracking app. We will now import all datasets and combine them on the staypoints / triplegs level\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Geolife\n",
    "Geolife is an important benchmark dataset. Trackintel therefore offers a dedicated function that reads in the Geolife dataset. The import function takes care of the required column format and names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:13<00:00,  1.38s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elevation</th>\n",
       "      <th>tracked_at</th>\n",
       "      <th>geom</th>\n",
       "      <th>user_id</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149.9616</td>\n",
       "      <td>2008-10-23 02:53:04+00:00</td>\n",
       "      <td>POINT (116.31842 39.98470)</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149.9616</td>\n",
       "      <td>2008-10-23 02:53:10+00:00</td>\n",
       "      <td>POINT (116.31845 39.98468)</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>149.9616</td>\n",
       "      <td>2008-10-23 02:53:15+00:00</td>\n",
       "      <td>POINT (116.31842 39.98469)</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    elevation                tracked_at                        geom  user_id  \\\n",
       "id                                                                             \n",
       "0    149.9616 2008-10-23 02:53:04+00:00  POINT (116.31842 39.98470)        0   \n",
       "1    149.9616 2008-10-23 02:53:10+00:00  POINT (116.31845 39.98468)        0   \n",
       "2    149.9616 2008-10-23 02:53:15+00:00  POINT (116.31842 39.98469)        0   \n",
       "\n",
       "    accuracy  \n",
       "id            \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trackintel.io.dataset_reader import read_geolife\n",
    "pfs_geolife, _ = read_geolife(path_to_geolife, print_progress=True)\n",
    "pfs_geolife.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate staypoints\n",
    "We generate staypoints from the positionfixes and define all staypoints as relevatn activities if they are longer than 25 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\henry\\.conda\\envs\\geodev\\lib\\site-packages\\trackintel\\preprocessing\\positionfixes.py:111: UserWarning: 1686 duplicates were dropped from your positionfixes. Dropping duplicates is recommended but can be prevented using the 'exclude_duplicate_pfs' flag.\n",
      "  warnings.warn(warn_str)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>started_at</th>\n",
       "      <th>finished_at</th>\n",
       "      <th>elevation</th>\n",
       "      <th>geom</th>\n",
       "      <th>is_activity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-10-23 03:03:45+00:00</td>\n",
       "      <td>2008-10-23 04:08:07+00:00</td>\n",
       "      <td>61.7220</td>\n",
       "      <td>POINT (116.29917 39.98341)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-10-23 04:32:52+00:00</td>\n",
       "      <td>2008-10-23 09:42:25+00:00</td>\n",
       "      <td>53.9496</td>\n",
       "      <td>POINT (116.32451 39.99967)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-10-23 11:10:42+00:00</td>\n",
       "      <td>2008-10-24 02:10:09+00:00</td>\n",
       "      <td>26.8224</td>\n",
       "      <td>POINT (116.32105 40.00917)</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id                started_at               finished_at  elevation  \\\n",
       "id                                                                           \n",
       "0         0 2008-10-23 03:03:45+00:00 2008-10-23 04:08:07+00:00    61.7220   \n",
       "1         0 2008-10-23 04:32:52+00:00 2008-10-23 09:42:25+00:00    53.9496   \n",
       "2         0 2008-10-23 11:10:42+00:00 2008-10-24 02:10:09+00:00    26.8224   \n",
       "\n",
       "                          geom  is_activity  \n",
       "id                                           \n",
       "0   POINT (116.29917 39.98341)         True  \n",
       "1   POINT (116.32451 39.99967)         True  \n",
       "2   POINT (116.32105 40.00917)         True  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract staypoints\n",
    "pfs_geolife, sp_geolife = pfs_geolife.as_positionfixes.generate_staypoints(\n",
    "    gap_threshold=24 * 60, include_last=True, print_progress=True, dist_threshold=200, time_threshold=30, n_jobs=4\n",
    ")\n",
    "\n",
    "# add activity flag to staypoints\n",
    "sp_geolife = sp_geolife.as_staypoints.create_activity_flag(method=\"time_threshold\", time_threshold=25)\n",
    "sp_geolife.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate triplegs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 25 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>started_at</th>\n",
       "      <th>finished_at</th>\n",
       "      <th>geom</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-10-23 02:53:04+00:00</td>\n",
       "      <td>2008-10-23 03:03:40+00:00</td>\n",
       "      <td>LINESTRING (116.31842 39.98470, 116.31845 39.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-10-23 04:08:07+00:00</td>\n",
       "      <td>2008-10-23 04:32:47+00:00</td>\n",
       "      <td>LINESTRING (116.28680 39.99578, 116.28545 39.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-10-23 09:42:25+00:00</td>\n",
       "      <td>2008-10-23 11:10:37+00:00</td>\n",
       "      <td>LINESTRING (116.32016 40.00478, 116.32039 40.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id                started_at               finished_at  \\\n",
       "id                                                                \n",
       "0         0 2008-10-23 02:53:04+00:00 2008-10-23 03:03:40+00:00   \n",
       "1         0 2008-10-23 04:08:07+00:00 2008-10-23 04:32:47+00:00   \n",
       "2         0 2008-10-23 09:42:25+00:00 2008-10-23 11:10:37+00:00   \n",
       "\n",
       "                                                 geom  \n",
       "id                                                     \n",
       "0   LINESTRING (116.31842 39.98470, 116.31845 39.9...  \n",
       "1   LINESTRING (116.28680 39.99578, 116.28545 39.9...  \n",
       "2   LINESTRING (116.32016 40.00478, 116.32039 40.0...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pfs_geolife, tpls_geolife = pfs_geolife.as_positionfixes.generate_triplegs(sp_geolife, method=\"between_staypoints\", gap_threshold=25)\n",
    "tpls_geolife.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfcb3c2",
   "metadata": {},
   "source": [
    "#### Included tracking studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Green Class 1 & 2\n",
    "The other datasets are stored in a postgis database and were already preprocessed to staypoints (static behavior) and triplegs (movement). To use them with trackintel, the data has to be adjusted to the data model. This means to create a geodataframe with the correct column names and timezone aware timestamps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Staypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_list = []\n",
    "for study in ['gc1', 'gc2']:\n",
    "    # download data\n",
    "    sp_temp = gpd.GeoDataFrame.from_postgis(sql=f\"SELECT * FROM {study}.staypoints\",\n",
    "        con=con_gc, geom_col=\"geometry_raw\", index_col=\"id\")\n",
    "    \n",
    "    # transform to trackintel dataframe\n",
    "    sp_temp = ti.io.read_staypoints_gpd(sp_temp, geom_col='geom', tz='UTC', crs=CRS_WGS84,\n",
    "                                                 mapper={\"geometry_raw\": \"geom\", \"purpose_validated\": \"activity_label\"})\n",
    "\n",
    "    # green class specific definition of activities\n",
    "    sp_temp = sp_temp.as_staypoints.create_activity_flag(method=\"time_threshold\", time_threshold=25)\n",
    "    meaningful_purpose = ~sp_temp[\"activity_label\"].isin([\"wait\", \"unknown\"])\n",
    "    sp_temp.loc[meaningful_purpose, 'is_activity'] = True\n",
    "    \n",
    "    # keep study as attribute\n",
    "    sp_temp['study'] = study_mapping[study]\n",
    "    \n",
    "    sp_list.append(sp_temp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### triplegs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpls_list = []\n",
    "for study in ['gc1', 'gc2']:\n",
    "    # downlaod data\n",
    "    tpls_temp = gpd.GeoDataFrame.from_postgis(\n",
    "        sql=f\"SELECT * FROM {study}.triplegs where ST_isValid(geometry) limit 1000\",con=con_gc,\n",
    "        crs=CRS_WGS84, geom_col=\"geometry\", index_col=\"id\")\n",
    "    # transform to trackintel dataframe\n",
    "    tpls_temp = ti.io.read_triplegs_gpd(tpls_temp, geom_col='geom',\n",
    "        crs=CRS_WGS84,\n",
    "        tz='UTC',\n",
    "        mapper={\"geometry\": \"geom\"})\n",
    "\n",
    "    tpls_list.append(tpls_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import yumuv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### staypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_yumuv = ti.io.read_staypoints_postgis(\"select * from yumuv.staypoint limit 100\", con=con_yumuv, geom_col='geometry', \n",
    "                                         crs=CRS_WGS84, index_col=\"id\", tz=\"UTC\",\n",
    "                                        mapper={'user_fk': 'user_id'})\n",
    "\n",
    "sp_yumuv = sp_yumuv.rename({'geometry': 'geom'}, axis=1).set_geometry('geom')\n",
    "sp_yumuv['study'] = 'yumuv'\n",
    "sp_yumuv = sp_yumuv.as_staypoints.create_activity_flag(time_threshold=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### triplegs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Query missing geometry column 'geometry'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-603babd0c9b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m tpls_yumuv = ti.io.postgis.read_triplegs_postgis(\"select * FROM yumuv_graph_rep.triplegs\", con=con_yumuv, geom_col='geometry', \n\u001b[0m\u001b[0;32m      2\u001b[0m                                                  \u001b[0mcrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCRS_WGS84\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"UTC\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                                 )\n\u001b[0;32m      4\u001b[0m \u001b[0mtpls_yumuv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtpls_yumuv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'geometry'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'geom'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_geometry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'geom'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgeom_not_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m~\u001b[0m\u001b[0mtpls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_valid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\geodev\\lib\\site-packages\\trackintel\\io\\postgis.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# only do something if connection string\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\geodev\\lib\\site-packages\\trackintel\\io\\postgis.py\u001b[0m in \u001b[0;36mread_triplegs_postgis\u001b[1;34m(sql, con, geom_col, crs, index_col, coerce_float, parse_dates, params, chunksize, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m     ...                                    started_at=\"start_time\", finished_at=\"end_time\", user_id=\"USER\")\n\u001b[0;32m    209\u001b[0m     \"\"\"\n\u001b[1;32m--> 210\u001b[1;33m     tpls = gpd.GeoDataFrame.from_postgis(\n\u001b[0m\u001b[0;32m    211\u001b[0m         \u001b[0msql\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m         \u001b[0mcon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\geodev\\lib\\site-packages\\geopandas\\geodataframe.py\u001b[0m in \u001b[0;36mfrom_postgis\u001b[1;34m(cls, sql, con, geom_col, crs, index_col, coerce_float, parse_dates, params, chunksize)\u001b[0m\n\u001b[0;32m    680\u001b[0m         \"\"\"\n\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 682\u001b[1;33m         df = geopandas.io.sql._read_postgis(\n\u001b[0m\u001b[0;32m    683\u001b[0m             \u001b[0msql\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[0mcon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\geodev\\lib\\site-packages\\geopandas\\io\\sql.py\u001b[0m in \u001b[0;36m_read_postgis\u001b[1;34m(sql, con, geom_col, crs, index_col, coerce_float, parse_dates, params, chunksize)\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         )\n\u001b[1;32m--> 163\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_df_to_geodf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgeom_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgeom_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\geodev\\lib\\site-packages\\geopandas\\io\\sql.py\u001b[0m in \u001b[0;36m_df_to_geodf\u001b[1;34m(df, geom_col, crs)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgeom_col\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Query missing geometry column '{}'\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeom_col\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[0mgeoms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgeom_col\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Query missing geometry column 'geometry'"
     ]
    }
   ],
   "source": [
    "tpls_yumuv = ti.io.postgis.read_triplegs_postgis(\"select * FROM yumuv_graph_rep.triplegs\", con=con_yumuv, geom_col='geometry', \n",
    "                                                 crs=CRS_WGS84, index_col=\"id\", tz=\"UTC\", \n",
    "                                                )\n",
    "tpls_yumuv = tpls_yumuv.rename({'geometry': 'geom'}, axis=1).set_geometry('geom')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom_not_valid = ~tpls.geometry.is_valid\n",
    "print(\"invalid triplegs\", sum(geom_not_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sp_gc1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-cb4574e71dbb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvalid_tstamp_flag_sp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msp_gc1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstarted_at\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0msp_gc1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinished_at\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mvalid_tstamp_flag_tpls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msp_gc2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstarted_at\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0msp_gc2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinished_at\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m~\u001b[0m \u001b[0mvalid_tstamp_flag_sp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mvalid_tstamp_flag_tpls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sp_gc1' is not defined"
     ]
    }
   ],
   "source": [
    "valid_tstamp_flag_sp = sp_gc1.started_at <= sp_gc1.finished_at\n",
    "valid_tstamp_flag_tpls = sp_gc2.started_at <= sp_gc2.finished_at\n",
    "print((~ valid_tstamp_flag_sp).sum(), (~valid_tstamp_flag_tpls).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp_list = []\n",
    "for ix, study in enumerate(studies):\n",
    "    sql = f\"SELECT * FROM {study}.staypoints order by started_at\"\n",
    "    df_temp = ti.io.read_staypoints_postgis(sql, con, index_col=\"id\", geom_col=\"geom\")\n",
    "    \n",
    "    df_temp['study'] = study_mapping[study]\n",
    "    df_temp.index = df_temp.index + ix * 10e7 # ensure unique index over studies\n",
    "    \n",
    "    df_temp.rename({'purpose': 'activity_label', 'activity': 'is_activity'}, axis=1, inplace=True)\n",
    "    if study in ['gc1', 'gc2']:\n",
    "        df_temp['activity_label'] = df_temp['activity_label'].apply(eval)\n",
    "        #print(study, df_temp.activity_label.unique())\n",
    "        \n",
    "    df_temp_list.append(df_temp)\n",
    "\n",
    "staypoints = pd.concat(df_temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten activity label (gc1 preprocessing)\n",
    "def flatten_activity(activity_label):\n",
    "    if isinstance(activity_label, list):\n",
    "        if 'home' in activity_label:\n",
    "            return 'home'\n",
    "        elif 'work' in activity_label:\n",
    "            return 'work'\n",
    "        else:\n",
    "            return activity_label[0]\n",
    "    else:\n",
    "        return activity_label\n",
    "    \n",
    "staypoints['activity_label'] = staypoints['activity_label'].apply(flatten_activity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "staypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_study_matching = staypoints[['user_id', 'study']].drop_duplicates()\n",
    "user_study_matching = user_study_matching.set_index('user_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge triplegs\n",
    "\n",
    "#### Todo: \n",
    "- drop additional columns\n",
    "- name mode column `mode` for all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get triplegs\n",
    "df_temp_list = []\n",
    "for ix, study in enumerate(studies):\n",
    "    print(study)\n",
    "    sql = f\"SELECT * FROM {study}.triplegs order by started_at\"\n",
    "    df_temp = ti.io.read_triplegs_postgis(sql, con, index_col=\"id\", geom_col=\"geom\")\n",
    "    df_temp['study'] = study_mapping[study]\n",
    "    df_temp.index = df_temp.index + ix * 10e7 # ensure unique index over studies\n",
    "    df_temp.rename({'mode_validated': 'mode', 'track_mode_corrected': 'mode'}, axis=1, inplace=True)\n",
    "    df_temp_list.append(df_temp)\n",
    "\n",
    "triplegs = pd.concat(df_temp_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "staypoints, triplegs, trips = ti.preprocessing.triplegs.generate_trips(staypoints=staypoints, triplegs=triplegs,\n",
    "                                                                       gap_threshold=15, add_geometry=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create tours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips, tours = ti.preprocessing.generate_tours(trips, staypoints=staypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = trips.join(user_study_matching, on='user_id')\n",
    "tours = tours.join(user_study_matching, on='user_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "staypoints, locations = ti.preprocessing.generate_locations(staypoints, epsilon=30, num_samples=1, \n",
    "                                                distance_metric='haversine', print_progress=True,\n",
    "                                                n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = locations.join(user_study_matching, on='user_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_df = pd.DataFrame(index=study_mapping.values())\n",
    "\n",
    "nr_user = trips['user_id'].nunique()\n",
    "overview_df['nr_user'] = nr_user\n",
    "\n",
    "# nb staypooints\n",
    "overview_df['nr_sp'] = staypoints.groupby(by=['study']).size()\n",
    "overview_df['nr_staypoints_per_user'] = overview_df['nr_sp']/nr_user\n",
    "\n",
    "# nb triplegs\n",
    "overview_df['nr_tpls'] = triplegs.groupby(by=['study']).size()\n",
    "overview_df['nr_triplegs_per_user'] = overview_df['nr_tpls']/nr_user\n",
    "\n",
    "# nb trips\n",
    "overview_df['nr_trips'] = trips.groupby(by=['study']).size()\n",
    "overview_df['nr_trips_per_user'] = overview_df['nr_trips']/nr_user\n",
    "# nb locations\n",
    "\n",
    "overview_df['nr_loc'] = locations.groupby(by=['study']).size()\n",
    "overview_df['nr_locations_per_user'] = overview_df['nr_loc']/nr_user\n",
    "\n",
    "# nb tours\n",
    "overview_df['nr_tours'] = tours.groupby(by=['study']).size()\n",
    "overview_df['nr_tours_per_user'] = overview_df['nr_tours']/nr_user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89b0e332",
   "metadata": {},
   "source": [
    "## 3) Add further details\n",
    "\n",
    "* How many trips comprise one tour on average? How many triplegs comprise a trip?\n",
    "* What is the average trip duration / distance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe37b5a",
   "metadata": {},
   "source": [
    "#### Number of hops in tours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tours['nb_hops'] = tours[\"trips\"].apply(lambda x: len(x))\n",
    "overview_df['avg_hops_tours'] =  tours.groupby('study')['nb_hops'].mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bd0f1f",
   "metadata": {},
   "source": [
    "#### Trip duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " (trips['finished_at'] - trips['started_at']).dt.total_seconds() / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips['duration_s'] = (trips['finished_at'] - trips['started_at']).dt.total_seconds() / 3600\n",
    "overview_df[[\"mean_trip_dur\", \"std_trip_dur\"]] = trips.groupby('study')['duration_s'].aggregate(['mean', 'std'])\n",
    "overview_df = overview_df.round({'mean_trip_dur': 2, 'std_trip_dur': 2})\n",
    "overview_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997097ad",
   "metadata": {},
   "source": [
    "#### Overall tracking period and number of trips per day per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_times_by_user = trips.groupby(['study', 'user_id']).aggregate({'started_at': 'min', 'finished_at': 'max'})\n",
    "duration_by_user = (min_max_times_by_user['finished_at'] - min_max_times_by_user['started_at']).dt.total_seconds() / (3600 * 24)\n",
    "overview_df[[\"mean_tracking_period\", \"std_tracking_period\"]] = duration_by_user.groupby('study').aggregate(['mean', 'std'])\n",
    "overview_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average trips per day on days with data\n",
    "trips_temp = trips.set_index('started_at')\n",
    "nr_trips_per_user_per_day = trips_temp.groupby(['study', 'user_id', pd.Grouper(freq='D')]).size().groupby('study').mean() \n",
    "overview_df['nr_trips_per_user_per_day'] = nr_trips_per_user_per_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average trips per day over full tracking period\n",
    "nr_trips_per_user_per_day = (trips.groupby(['study', 'user_id']).size() / duration_by_user).groupby('study').mean()\n",
    "\n",
    "# there are some outliers that have tracked <<< 1 day (due to the limit set by me)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a545b0b4",
   "metadata": {},
   "source": [
    "#### Trip distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', None)\n",
    "#triplegs.geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ti.preprocessing.smoothen_triplegs(triplegs, tolerance=0.1, preserve_topology=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplegs['length_in_m'] = ti.geogr.distances.calculate_haversine_length(triplegs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_per_trip = triplegs.groupby(['study', 'trip_id']).agg({\"trip_id\": \"count\", \"length_in_m\":\"sum\"})\n",
    "overview_df[[\"nr_legs_per_trip\", \"avg_trip_length\", \"std_trip_length\"\n",
    "            ]] = metrics_per_trip.groupby('study').agg({'trip_id': 'mean', 'length_in_m': [\"mean\", \"std\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d48409",
   "metadata": {},
   "source": [
    "#### Tracking quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplegs_staypoints = pd.concat([triplegs, staypoints])\n",
    "tracking_quality_by_user_study = triplegs_staypoints.groupby('study').apply(temporal_tracking_quality)\n",
    "overview_df[[\"mean_tracking_quality\", \"std_tracking_quality\"]] = tracking_quality_by_user_study.groupby('study').agg(['mean', 'std'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cac160c",
   "metadata": {},
   "source": [
    "## 4) Finalize results in two tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e3af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make DataFrame from out_dict and save to csv\n",
    "#df = pd.DataFrame(out_dict).swapaxes(1,0)\n",
    "#df.to_csv(os.path.join(out_path, \"trackintel_casestudy_df.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c4be24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load df\n",
    "#df = pd.read_csv(os.path.join(out_path, \"trackintel_casestudy_df.csv\"), index_col=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3a83c2",
   "metadata": {},
   "source": [
    "#### 4.1) Table with simple dataset stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_df[[\"nr_user\",\"mean_tracking_period\", \"std_tracking_period\", \"nr_loc\", \"nr_sp\", \"nr_tpls\", \"nr_trips\", \"nr_tours\"]]\n",
    "overview_df.fillna(0, inplace=True)\n",
    "overview_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic info\n",
    "df_basic = overview_df[[\"nr_user\",\"mean_tracking_period\", \"std_tracking_period\", \"nr_loc\", \"nr_sp\", \"nr_tpls\", \"nr_trips\", \"nr_tours\"]].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c159b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_basic[\"Tracking period (std)\"] = df_basic.apply(lambda x: f\"{x['mean_tracking_period']} ({x['std_tracking_period']})\", axis=1)\n",
    "df_basic[\"Available\"] = \"Staypoints, Triplegs\"\n",
    "df_basic[\"Study type\"] = \"GNSS (app)\"\n",
    "\n",
    "\n",
    "\n",
    "# rename columns and index\n",
    "df_basic = df_basic.rename(columns={\"Available\": \"Input\", \"nr_user\": \"Users\", \"nr_loc\": \"Locations\", \"nr_sp\": \"Staypoints\", \"nr_tpls\": \"Triplegs\", \n",
    "                        \"nr_trips\": \"Trips\", \"nr_tours\": \"Tours\"}, \n",
    "                        index=study_mapping).drop(columns=[\"mean_tracking_period\", \"std_tracking_period\"])\n",
    "# select the columns in the right order\n",
    "df_basic = df_basic[[\"Users\", 'Tracking period (std)' , \"Input\", \"Study type\", \"Locations\", \"Staypoints\", \"Triplegs\", \"Trips\", \"Tours\"]]\n",
    "\n",
    "df_basic\n",
    "# print(df_basic.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22dde33",
   "metadata": {},
   "source": [
    "#### 4.2) Table with analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740dd475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis table\n",
    "detailed = overview_df[[\"nr_trips_per_user_per_day\", \"mean_trip_dur\", \"std_trip_dur\", \"avg_hops_tours\", \"nr_legs_per_trip\", \"avg_trip_length\", \"std_trip_length\", \"mean_tracking_quality\", \"std_tracking_quality\"]]\n",
    "detailed = detailed.round(2)\n",
    "# Incorporate mean and std in one cell\n",
    "detailed[\"Trip distance (std)\"] = detailed.apply(lambda x: f\"{int(x['avg_trip_length'])} ({int(x['std_trip_length'])})\", axis=1)\n",
    "detailed[\"Trip duration (std)\"] = detailed.apply(lambda x: f\"{x['mean_trip_dur']} ({x['std_trip_dur']})\", axis=1)\n",
    "detailed[\"Tracking quality (std)\"] = detailed.apply(lambda x: f\"{x['mean_tracking_quality']} ({x['std_tracking_quality']})\", axis=1)\n",
    "\n",
    "detailed = detailed.rename(columns={\"nr_trips_per_user_per_day\": \"Trips per day\", \n",
    "                                   \"avg_hops_tours\": \"Trips per tour\", \n",
    "                                   \"nr_legs_per_trip\": \"Legs per trip\"}, \n",
    "                          index={\"gc1\":\"Green Class 1\", \"gc2\": \"Green Class 2\", \"yumuv_graph_rep\": \"Yumuv\", \"geolife\":\"Geolife\"}\n",
    "                          ).drop([\"avg_trip_length\", \"std_trip_length\", \"mean_tracking_quality\", \"std_tracking_quality\",\n",
    "                                  \"mean_trip_dur\", \"std_trip_dur\"\n",
    "                                 ], axis=1)\n",
    "\n",
    "detailed\n",
    "# print(detailed.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2618bd0e",
   "metadata": {},
   "source": [
    "## 5) KDE plot for user tracking quality distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = tracking_quality_by_user_study.reset_index(drop=False, level=0).drop('user_id', axis=1)\n",
    "new_df = new_df.pivot(columns='study', values='quality')\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743a508a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#for key in [\"gc1\",\"gc2\",  \"geolife\", \"yumuv_graph_rep\"]:\n",
    " #   study = study_mapping[key]\n",
    "  #  new_df[study] = tracking_quality_dfs[key][\"quality\"]\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.rcParams.update({\"font.size\": 15})\n",
    "g = sns.kdeplot(data=new_df, fill=True, alpha=.3, legend=True, common_grid=True)\n",
    "# sns.histplot(data=new_df, bins=100,common_norm=True, stat=\"density\", kde=False)\n",
    "plt.ylabel(\"Density (users)\")\n",
    "plt.xlabel(\"Tracking quality\")\n",
    "sns.move_legend(g, \"upper left\")\n",
    "plt.xlim(0, 1)\n",
    "#plt.savefig(os.path.join(out_path, \"tracking_quality_kde.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf20e5d",
   "metadata": {},
   "source": [
    "## 6) Modal split dataset comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff4a2c6",
   "metadata": {},
   "source": [
    "#### Main plotting function to compare the modal split of several studies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e6a62c",
   "metadata": {},
   "source": [
    "#### Apply Trackintel function to get the modes for Geolife"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_geolife = triplegs['study'] == 'Geolife'\n",
    "tpls_geolife = triplegs[is_geolife]\n",
    "tpls_geolife"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2babfc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "is_geolife = triplegs['study'] == 'Geolife'\n",
    "\n",
    "\n",
    "triplegs[is_geolife] = ti.analysis.labelling.predict_transport_mode(triplegs[is_geolife])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to map the mode labels from GC1 / GC2 / Yumuv to the ones from geolife\n",
    "mode_to_category = {\n",
    "    'Mode::Bicycle': 'slow',\n",
    "     'Mode::Car': 'motorized',\n",
    "     'Mode::Train': 'fast',\n",
    "    'Mode::Walk': 'slow',\n",
    "    'Mode::Tram': 'motorized',\n",
    "    'Mode::Bus': 'motorized',\n",
    "    'Mode::Airplane': 'fast',\n",
    "    'Mode::Coach': 'motorized',\n",
    "    'Mode::Ebicycle': 'slow',\n",
    "    'Mode::Boat': 'slow',\n",
    "    'Mode::Ecar': 'motorized',\n",
    "    \"fast_mobility\": \"fast\",\n",
    "    \"motorized_mobility\": \"motorized\",\n",
    "    \"slow_mobility\": \"slow\",\n",
    "    \"airplane\": \"fast\", \n",
    "    \"bicycle\": \"slow\",\n",
    "    \"boat\": \"slow\",\n",
    "    \"bus\": \"motorized\",\n",
    "    \"car\": \"motorized\",\n",
    "    \"coach\": \"motorized\",\n",
    "    \"ebicycle\": \"slow\",\n",
    "    \"kick_scooter\": \"slow\",\n",
    "    \"ecar\": \"motorized\",\n",
    "    \"motorbike\": \"motorized\",\n",
    "    \"ski\": \"slow\",\n",
    "    \"train\": \"fast\",\n",
    "    \"tram\": \"motorized\",\n",
    "    \"walk\": \"slow\",\n",
    "    \"fast\": \"fast\",\n",
    "    \"motorized\": \"motorized\",\n",
    "    \"slow\": \"slow\"\n",
    "}\n",
    "\n",
    "triplegs['mode'] = triplegs['mode'].map(mode_to_category)\n",
    "triplegs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplegs.dropna(subset=['mode'], inplace=True)\n",
    "triplegs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count\n",
    "modal_split_count = triplegs.groupby('study').apply(calculate_modal_split, metric='count', norm=True)\n",
    "modal_split_count = modal_split_count.droplevel(1)\n",
    "modal_split_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duration\n",
    "modal_split_duration = triplegs.groupby('study').apply(calculate_modal_split, metric='duration', norm=True)\n",
    "modal_split_duration = modal_split_duration.droplevel(1)\n",
    "modal_split_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modal_split = triplegs.groupby('study').apply(calculate_modal_split, metric='distance', norm=True) https://github.com/geopandas/geopandas/issues/1777\n",
    "modal_split_list = []\n",
    "for study, tpls in triplegs.groupby('study'):\n",
    "    modal_split_distance = calculate_modal_split(tpls, metric='distance', norm=True)\n",
    "    modal_split_distance['study'] = study\n",
    "    modal_split_list.append(modal_split_distance)\n",
    "    \n",
    "modal_split_distance = pd.concat(modal_split_list).set_index('study')\n",
    "modal_split_distance\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614928eb",
   "metadata": {},
   "source": [
    "### Get modal split for each study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf55d360",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplegs['mode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6138154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "triplegs\n",
    "\n",
    "# extent mode_to_category mapping with the upper case / colon versions\n",
    "#further_cols = list(modal_split_count[\"gc1\"].columns)\n",
    "#for col in further_cols:\n",
    "#    mode_to_category[col] = mode_to_category[col.split(\"::\")[1].lower()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['#1D2F6F', '#8390FA', '#6EAF46', '#FAC748']\n",
    "color = dict(zip(['fast', 'motorized', 'slow'], ['#1D2F6F', '#8390FA', '#6EAF46']))\n",
    "color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_modal_split_comparison(name_df, modal_split_df):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    modal_split_df.plot.bar(stacked=True, color=color, ax=ax)\n",
    "    fs = 16\n",
    "    plt.legend(loc=\"upper right\", framealpha=1, fontsize=fs)\n",
    "    plt.xlabel(\"Dataset\", fontsize=fs)\n",
    "    plt.ylabel(\"Modal split\", fontsize=fs)\n",
    "    plt.xticks(fontsize=fs)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(out_path, f\"modal_split_all_{name_df}.pdf\"), bbox_inches='tight')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting loop\n",
    "for name_df, modal_split_df in zip([\"count\", \"duration\", \"distance\"],[modal_split_count, modal_split_duration, modal_split_distance]):\n",
    "    plot_modal_split_comparison(name_df, modal_split_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cfe2d1",
   "metadata": {},
   "source": [
    "## 7) Home / Work labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1489b182",
   "metadata": {},
   "source": [
    "#### Collect work and home staypoints for GC1 and GC2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd71756",
   "metadata": {},
   "source": [
    "#### Compute staypoint purpose for Geolife and Yumuv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yumuv_geolife_flag = staypoints['study'].isin(['Geolife', 'Yumuv'])\n",
    "staypoints_wo_purpose = staypoints[yumuv_geolife_flag].copy()\n",
    "\n",
    "pre_filter_kwargs = {'agg_level': 'dataset',\n",
    "    'thresh_sp' : 0,\n",
    "'thresh_loc' : 0,\n",
    "'thresh_sp_at_loc' : 0,\n",
    "'thresh_loc_time' : \"0h\",\n",
    "'thresh_loc_period' : \"0h\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "staypoints_wo_purpose = ti.analysis.location_identifier(staypoints_wo_purpose, method=\"FREQ\", **pre_filter_kwargs)\n",
    "staypoints.activity_label.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_home = staypoints[staypoints['activity_label'] == 'home']\n",
    "sp_work = staypoints[staypoints['activity_label'] == 'work']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9361815e",
   "metadata": {},
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for sp_purpose, name in zip([sp_home, sp_work], [\"home\", \"work\"]):\n",
    "sp_study = sp_home.copy()\n",
    "name = 'home'\n",
    "\n",
    "home_slots = []\n",
    "\n",
    "\n",
    "# init result array\n",
    "minute_slots = np.zeros(24 * 60)\n",
    "\n",
    "# convert timestamp columns\n",
    "sp_study[\"started_at\"] = pd.to_datetime(sp_study[\"started_at\"], utc=True)\n",
    "sp_study[\"finished_at\"] = pd.to_datetime(sp_study[\"finished_at\"], utc=True)\n",
    "# geolife flag\n",
    "geolife_flag = sp_study['study'] == 'Geolife'\n",
    "\n",
    "#sp_study.loc[geolife_flag, \"started_at\"]  = sp_study.loc[geolife_flag, \"started_at\"].dt.tz_convert(\"Europe/Paris\")\n",
    "#sp_study.loc[geolife_flag, \"finished_at\"]  = sp_study.loc[geolife_flag, \"finished_at\"].dt.tz_convert(\"Europe/Paris\")\n",
    "\n",
    "sp_study.loc[:, \"started_at\"]  = sp_study.loc[:, \"started_at\"].dt.tz_convert(\"Europe/Paris\")\n",
    "sp_study.loc[:, \"finished_at\"]  = sp_study.loc[:, \"finished_at\"].dt.tz_convert(\"Europe/Paris\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_colwidth', None)\n",
    "#sp_study_.sort_index()['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_study.finished_at.max()\n",
    "t_start = sp_study.started_at\n",
    "t_end = sp_study.finished_at\n",
    "sp_study_ = sp_study[['started_at', 'finished_at', 'study']].copy()\n",
    "#sp_study['date_range'] = df.apply(lambda x: pd.date_range(x[\"start_date\"], x[\"end_date\"]), axis=1)\n",
    "\n",
    "sp_study_[\"date\"] = sp_study_.apply(lambda x: pd.date_range(x[\"started_at\"], x[\"finished_at\"],  freq='min'), axis=1)\n",
    "sp_study_expl = sp_study_.explode(\"date\", ignore_index=True).drop(columns=[\"started_at\", \"finished_at\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_by_minute = pd.DataFrame(sp_study_expl.groupby(['study', sp_study_expl.date.dt.hour, sp_study_expl.date.dt.minute]).size())\n",
    "count_by_minute.index.rename(['study', 'hour', 'minute'], inplace=True)\n",
    "count_by_minute.reset_index(inplace=True)\n",
    "count_by_minute['minute_of_day'] = count_by_minute['hour'] * 60 + count_by_minute['minute']\n",
    "\n",
    "count_by_minute_pivot = count_by_minute.pivot(columns='study', index='minute_of_day', values=0)\n",
    "count_by_minute_pivot.plot()\n",
    "plt.xticks(np.arange(0, len(minute_slots), 120), np.arange(0,24,2))\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.ylabel=(f\"Fraction of {name} staypoints covering time point\")\n",
    "plt.xlabel(\"Hour of the day\")\n",
    "# plt.savefig(os.path.join(out_path, f\"plot_activity_distribution_{name}.pdf\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "home_slots = count_by_minute_pivot.values.transpose()\n",
    "plt.imshow(home_slots, aspect=100)\n",
    "for i in range(4):\n",
    "    plt.plot([0, home_slots.shape[1]], [i+.5, i+.5], c=\"black\", lw=1)\n",
    "plt.xlim(0, 24)\n",
    "plt.yticks(np.arange(4), map(lambda x: study_mapping[x], studies))\n",
    "plt.xlabel(\"Hour of the day\")\n",
    "ax.xaxis.tick_top()\n",
    "ax.xaxis.tickpad = -2\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.xticks(np.arange(0, len(minute_slots), 120), np.arange(0,24, 2))\n",
    "# ax.set_xticklabels(np.arange(0, len(minute_slots), 120), np.arange(0,24, 2))\n",
    "cbar = plt.colorbar(orientation=\"horizontal\", ax=ax, aspect=16) #anchor=(-1, -1))\n",
    "cbar.set_label(f\"Fraction of {name} staypoints at time t\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig(os.path.join(out_path, f\"imshow_act_distribution_{name}.pdf\"), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff36281",
   "metadata": {},
   "source": [
    "## 8) Single user visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point, Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min = 116.2\n",
    "x_max = 116.5\n",
    "y_min = 39.8\n",
    "y_max = 40.1\n",
    "sw = Point(x_min, y_min)\n",
    "se = Point(x_max, y_min)\n",
    "ne = Point(x_max, y_max)\n",
    "nw = Point(x_min, y_max)\n",
    "\n",
    "study_area = gpd.GeoDataFrame(columns=['geometry'], data=[Polygon([sw, se, ne, nw])], geometry='geometry', crs=\"EPSG:4326\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4126224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to limit the spatial extend of the shown region\n",
    "def get_in_range(linestring):\n",
    "    x, y = linestring.xy\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    if all(y>39.8) and all(y< 41): # 9.8, 9.3, 4.6, # all(x < 9.8) and all(x>9.3)\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "#trackintel.preprocessing.filter.spatial_filter(source, areas, method='within', re_project=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70110f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Geolife data of one user\n",
    "tpls_vis = triplegs[triplegs['user_id']==51].copy()\n",
    "tpls_vis = ti.preprocessing.filter.spatial_filter(triplegs, study_area, method='within')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get staypoints as well\n",
    "sp_vis = staypoints[staypoints['user_id']==51].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d91e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_vis = ti.preprocessing.filter.spatial_filter(sp_vis, study_area, method='within')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = f\"SELECT * FROM geolife.positionfixes WHERE user_id=51\"\n",
    "pfs_vis = ti.io.read_positionfixes_postgis(sql, con, index_col=\"id\")\n",
    "pfs_vis = ti.preprocessing.filter.spatial_filter(pfs_vis, study_area, method='within')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec1fb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "ti.visualization.plot_triplegs(tpls_vis, \n",
    "                              staypoints= sp_vis,\n",
    "                               plot_osm=True,\n",
    "                                positionfixes=pfs_vis,\n",
    "                              staypoints_radius=150,\n",
    "                              out_filename=os.path.join(out_path, \"geolife_tpls_sp_pfs\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c2a529",
   "metadata": {},
   "source": [
    "#### Plot only positionfixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385b1b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ti.visualization.plot_positionfixes(pfs_vis,\n",
    "                                   plot_osm=True,\n",
    "                                   out_filename=os.path.join(out_path, \"geolife_pfs\")\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8006fa",
   "metadata": {},
   "source": [
    "#### Plot staypoints with positionfixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78457064",
   "metadata": {},
   "outputs": [],
   "source": [
    "ti.visualization.plot_staypoints(sp_vis,\n",
    "    positionfixes=pfs_vis,\n",
    "                                plot_osm=True,\n",
    "                                 radius=150,\n",
    "                                out_filename=os.path.join(out_path, \"geolife_sp_pfs\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c48f7a",
   "metadata": {},
   "source": [
    "### 8.2) Modal split visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6107094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GC2 user\n",
    "\n",
    "tpls_vis = triplegs[triplegs['user_id']=='c9aa08e2-1a5d-4d41-ae62-6110a9072b23']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580a6493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename to mode\n",
    "tpls_vis[\"mode\"] = tpls_vis[\"mode_detected\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1057e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute modal split\n",
    "modal_split = calculate_modal_split(tpls_vis, freq=\"M\", metric='count', per_user=False, norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ee4b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# order the transport modes for colour choices\n",
    "column_order = [\"Mode::Car\", \"Mode::Bicycle\", \"Mode::Walk\", \"Mode::Bus\", \"Mode::Train\", \"Mode::Ecar\", \"Mode::Ebicycle\", \"Mode::Airplane\"]\n",
    "modal_split = modal_split[column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab14611",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "ax = ti.visualization.modal_split.plot_modal_split(modal_split, \n",
    "                                              date_fmt_x_axis='%b',\n",
    "                                              y_label='Percentage of daily count',\n",
    "                                              skip_xticks=0,\n",
    "                                              n_col_legend=4,\n",
    "                                              fs=20,\n",
    "                                              axis=ax,\n",
    "                                             borderaxespad=2\n",
    "                                             )\n",
    "fig.autofmt_xdate()\n",
    "plt.savefig(os.path.join(out_path, \"modal_split_count\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6115d1e6",
   "metadata": {},
   "source": [
    "#### Same for distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26113904",
   "metadata": {},
   "outputs": [],
   "source": [
    "modal_split = calculate_modal_split(tpls_vis, freq=\"M\", metric='distance', per_user=False, norm=True)\n",
    "modal_split = modal_split[column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87588a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "ax = ti.visualization.modal_split.plot_modal_split(modal_split, \n",
    "                                              date_fmt_x_axis='%b',\n",
    "                                              y_label='Percentage of daily distance',\n",
    "                                              skip_xticks=0,\n",
    "                                              n_col_legend=4,\n",
    "                                              fs=20,\n",
    "                                              axis=ax,\n",
    "                                             borderaxespad=2\n",
    "                                             )\n",
    "fig.autofmt_xdate()\n",
    "plt.savefig(os.path.join(out_path, \"modal_split_distance\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba3e112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
